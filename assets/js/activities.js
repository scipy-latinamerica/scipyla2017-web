var activities = window.activities = [
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Decentralized indexes for public genome databases",
    "abstract": "Searching sequences by content is currently limited in public avaliable databases like NCBI's GenBank, RefSeq and SRA. We use a data structure based on Sequence Bloom Trees and MinHashes to allow searching for similar datasets in these massive databases.",
    "description": "",
    "audience_level": "All",
    "author_id": "806614bee86a0bef3c22b15248cdc7dc",
    "tags": [
      "bioinformatics",
      "computational biology",
      "genomics",
      ""
    ],
    "id": "df49ac741992d33e50caeed2f9839ea6"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Using Snakemake for scientific workflow management",
    "abstract": "Rule-based description of workflows are best exemplified by Make, but it has shortcomings (mostly derived from being targeted at programmers and compiling code). Snakemake solves many of these problems, allowing easily deployment and specification of workflows.",
    "description": "",
    "audience_level": "All",
    "author_id": "806614bee86a0bef3c22b15248cdc7dc",
    "tags": [
      "bioinformatics",
      ""
    ],
    "id": "b766c1ece591584fbde8101ec103b696"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "When VR meets Internet of things: Life beyond second life",
    "abstract": "imagine the possibilities that can exist if we were to we combine the worlds of Virtual Reality and Internet of Things This session will enable people with minimal knowledge of VR and basic IoT boards(such as Arduino, Raspberry Pi) to experience the best of the IoT & VR worlds. \n\n\n",
    "description": "\"It gets even more interesting when virtual and augmented reality meets the Internet of Things.\"  — Phil Repp\r\n\r\n \r\n\r\nIoT is taking over the technology industry with a huge bang! Our focus is to make the IoT smarter and more suitable for human interaction. Virtual Reality is the next billion dollar industry and it is the future of the Entertainment, Gaming and Education Industry. Now, imagine the possibilities that can exist if we were to we combine the worlds of Virtual Reality and Internet of Things This session will enable people with minimal knowledge of VR and basic IoT boards(such as Arduino, Raspberry Pi) to experience the best of the IoT & VR worlds. \r\n\r\n\r\nFurthermore, attendees will experience a remote tele-robotic presence as they transport and assume the identity of a web-connected robot, tasked with monitoring and maintaining atmospheric conditions.\r\n\r\n\r\n Along with the view of the place, the robot will be monitoring the nearby surroundings such as temperature, humidity and light intensity which will be then displayed along with the scenario displayed by VR device. Thus by this audience will learn how to Combine IoT with VR and hence make their own smart telepresence system like Jarvis.\r\n\r\n\r\n \r\n\r\nBy the end of the session, the audience will gain an increased understanding of the VR and IoT landscape, as well as how these technologies can be combined to give them an experience in life that was previously never-before-possible. A short Q&A session will be held after the [talk/workshop].",
    "audience_level": "All",
    "author_id": "9ecf8d590a47f752e6dd8254f79acee7",
    "tags": [
      ""
    ],
    "id": "e666db3b61705fa7a94af15966f5963d"
  },
  {
    "talk_format": "Lightning Talk (~5-10 minutes)",
    "title": "Lessons Learned In Unit Testing or: How I stopped Listening To Developers And QA",
    "abstract": "Imagine a world where QA and Developers work together without friction or problems. In reality, we can come very close to this, but no matter what, one subject that always pops up: Unit Testing. Often, it becomes a battle between Developers and QA. Should we Unit Test? There is no correct answer.",
    "description": "Developers and QA often clash when it comes to the practice of Unit Testing. How are we going to do it? Who is going to do it? And sometimes even, Should we do it? Before this starts looking like the War of the Roses, let’s examine the core issues at hand, and, in the span of 5 to 10 minutes, come up with a quick fire list of ways that you can convince, or discourage, others to use Unit Testing in your context.\r\n\r\nAnybody that tells you that unit testing is something you should always do… well, they are dead wrong. The same goes for the other side of the argument. If somebody tells you that you should never do Unit Testing, hit them over the head with a saucepan. The core keyword for unit testing is context. Would it be beneficial for me to apply unit testing to my project? This is the question you will be able to answer in exchange for 10 minutes of your time. Both the QA and Development managers will thank you for your newfound wisdom.",
    "audience_level": "All",
    "author_id": "157480d535da04fc1fab2f03de98ee86",
    "tags": [
      "testing",
      "qa",
      "development",
      "unit testing",
      "unit tests",
      "teamwork",
      ""
    ],
    "id": "3eaa0f1f391e9620eed39c18e4bddd76"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Can you keep a secret? or Privacy in the Digital Age",
    "abstract": "Do you know what data is being collected, the implications of cross-processing streams of data from different sources, the power of metadata? There are no more secrets.\n\nInspired by “Data and Goliath: The Hidden Battles to Collect Your Data and Control Your World” by Bruce Schneier",
    "description": "Computers and the Internet-Of-Things generate data about our every move, passing thought or feeling. There is also a comprehensive set of data on our life’s context: our whereabouts, connections, physiological state, patterns of movement, and deeply ingrained subconscious behaviors.\r\n\r\nWhile that information may not be immediately visible or easy to learn from, it is created, collected and saved. Over time, the pile of data grows. The processing technologies become more sophisticated and powerful. The data that was originally “anonymous” becomes easily identifiable. And no data is ever “forgotten”.\r\n\r\nIn this session we will consider what data is being collected, the implications of cross-processing streams of data from different sources, and the power of metadata. There are no more secrets.\r\n\r\nInspired by “Data and Goliath: The Hidden Battles to Collect Your Data and Control Your World” by Bruce Schneier",
    "audience_level": "All",
    "author_id": "00147df918ba806f8d4d649f05b32e7e",
    "tags": [
      "speech recognition",
      "internet of things",
      "data mining",
      "mass media",
      "analytics as a service (aaas)",
      "big data",
      "social media",
      "data",
      "security",
      "privacy",
      ""
    ],
    "id": "32deb5daa90aa3236faf4668ae6b4c8d"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "A New Dawn of the Human Experience: Artificial Sentience and Fabricated Empathy in Cognitive Computing",
    "abstract": "Exploring how, through the anthropomorphizing of machines, we’re creating fabricated empathy that will change the human experience, how we’re asking machines to make ethical decisions they’re grossly unprepared to do, and why AI won’t create an apocalypse of robots who take over the world. Maybe.",
    "description": "In what is being called the “third era of computing,” cognitive computing is revolutionizing the relationship between humans and computers. Internet of Things is only the beginning. Artificial Intelligence is finally sprouting out of science fiction and blossoming into palpable technology. Cognitive systems are able to learn independently, build upon pre-programmed knowledge, understand natural language, and interact with human beings with reasoning and logic.\r\n\r\nIn this session Mark will explore how, through the anthropomorphizing of machines, we are creating an environment of fabricated empathy that will change the human experience, and how we are asking machines to make ethical decisions that they’re grossly unprepared to do. He will also discuss why Artificial Intelligence won’t create an apocalypse of robots who take over the world. Maybe.",
    "audience_level": "Intermediate",
    "author_id": "da37a9787d36bc974217f1ff852c8873",
    "tags": [
      "artificial intelligence",
      "ai",
      "cognitive computing",
      "robotics",
      "robots",
      "human experience",
      ""
    ],
    "id": "59d0a1ff98ba2ee0a7c7e7b8a9e5ee74"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "The best of R in Python",
    "abstract": "This talk will present the RPy2 library. The lib is used to run R code in Python. R is a free software environment for statistical computing and graphics. Python is a programming language that lets you work quickly and integrate systems more effectively. Why to choose one if you can have both?",
    "description": "This talk will present the RPy2 library. The lib is used to run R code in Python. R is a free software environment for statistical computing and graphics. Python is a programming language that lets you work quickly and integrate systems more effectively. Why to choose one if you can have both?\r\n\r\nExamples:\r\n  - How to bind R functions in python.\r\n  - How to run R code inside python.\r\n  - How to get data from R calls in python.",
    "audience_level": "All",
    "author_id": "1d0e63c82656ba189e55e4e6fb734346",
    "tags": [
      "R",
      "Python",
      "RPy2",
      "data science",
      ""
    ],
    "id": "b35686cb6229cd811c249cb45c862867"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Build text classification models ( CBOW and Skip-gram) with FastText in python",
    "abstract": "NLP is an exciting way to interpret the textual data especially when we know that computer neither speak nor understand any kind of human language. So, how do we represent each word of a language in such a unique numerical pattern and process it in quickest way possible. Answer is FastText library.",
    "description": "FastText has been open-sourced by Facebook in 2016 and with its release, it became the fastest and most accurate library in Python for text classification and word representation. It is to be seen as a substitute for gensim package's word2vec.  It includes the implementation of two extremely important methodologies in NLP i.e Continuous Bag of Words and Skip-gram model. Fasttext performs exceptionally well with supervised as well as unsupervised learning. \r\n\r\nThe tutorial will be divided in following four segments :\r\n\r\n1. 0-10 minutes: The talk will begin with explaining the difference between word embeddings generated by word2vec, Glove, Fasttext and how FastText beats all the other libraries with better accuracy and in lesser time.\r\n\r\n2. 10-30 minutes: The code will be shown and explained line by line for both the models (CBOW and Skip-gram) on a standard textual labeled dataset with the tips on hyper-parametric tuning to get the best possible results.\r\n\r\n3. 30-40 minutes: How to use the pre-trained word embeddings released by FastText on various languages and where to use them. Various use cases of what kind of problems can be solved using FastText in python.\r\n\r\n4. 40-45 minutes: For QA session.",
    "audience_level": "All",
    "author_id": "9289b08391643b55c0d09ac492bb06e1",
    "tags": [
      "open source",
      "facebook",
      "machinelearning",
      "python",
      "wordvector",
      "skipgram",
      "data science",
      "deeplearning",
      "fasttext",
      "naturallanguageprocessing",
      ""
    ],
    "id": "bbd815dd7b038356021fe46ecb1c2fd3"
  },
  {
    "talk_format": "Workshop (> 60 minutes)",
    "title": "Plotting and Programming in Python (Python Novice Gapminder)",
    "abstract": "This is a Software Carpentry new course which is in early stages of development. Due that we only have 1 day (not enough for a full official SWC workshop) is a good opportunity for trying new things and receive important feedback.  This course uses the very famous and relevant Gapminder dataset.",
    "description": "Is a Software Carpentry Lesson planned for one full day: 09:00-16:30\r\n - 06:15 hrs of class time\r\n - 0:45 min for lunch\r\n - 0:30 min total for two coffee breaks\r\n\r\n# Desired Results\r\n\r\nThe student will be able to answer the questions\r\n\r\n**How do I…**\r\n\r\n - …read tabular data?\r\n - …plot a single vector of values?\r\n - …create a time series plot?\r\n - …create one plot for each of several data sets?\r\n - …get extra data from a single data set for plotting?\r\n - …write programs I can read and re-use in future?\r\n \r\nAnd develop the following skills\r\n\r\n**I can…**\r\n\r\n - …write short scripts using loops and conditionals.\r\n - …write functions with a fixed number of parameters that return a single result.\r\n - …import libraries using aliases and refer to those libraries’ contents.\r\n - …do simple data extraction and formatting using Pandas.\r\n ",
    "audience_level": "Beginner",
    "author_id": "7bbdf7e75f91b6b1c36f89c106baf71f",
    "tags": [
      "data science",
      "basics",
      "Software Carpentry",
      ""
    ],
    "id": "768698dac5cbbaa884437495d298b0d0"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Detecting offensive messages using Deep Learning: A micro-service based approach",
    "abstract": "What are you doing to control abusive content on your platform? Can your current solution tell the difference between \"f\\*\\*king awesome\" and \"f\\*\\*king loser\"? Can it detect racist and sexist content?\n\nYou will learn how to build a deep learning based solution and deploy it as a micro-service.",
    "description": "This talk focuses on :\r\n\r\n- The shortcomings / common pitfalls of current approaches in terms of:\r\n  - Functionality\r\n  - Scalibility\r\n- Handling the ambiguities in defining offensive content\r\n- Using a Deep Learning based approach to detect offensive content\r\n- Production-izing the solution\r\n",
    "audience_level": "All",
    "author_id": "11666cbce9f44e9389caa6e274a1144f",
    "tags": [
      "python",
      "deep learning",
      "machine learning",
      "data science",
      "devops",
      "neural networks",
      "microservice",
      "containers",
      "Artificial Intelligence",
      "Deep learning",
      ""
    ],
    "id": "8e50dc82ee2ac9023c46a2a3ee999204"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "The Dark side of Internet of things",
    "abstract": "With the advent of Internet of things, monitoring and controlling electrical appliances over the internet has become a child's play. But are we really making our lives simpler or diving ourselves in a vast ocean which is getting deeper and deeper? ",
    "description": "In today's world where the security of our data of a major concern, the number of websites are always tracking what we search for, what we watch, our location and now when things are limited to only data, adding another dimension i.e. physical entities is really a big question.\r\n\r\nrom this talk audience will take away an understanding of the privacy concerns related to IoT, and how they may be putting their personal information at risk by connecting my physical entities to the internet. Is it really safe to connect things to the internet?\r\n\r\nThere are two ways in which the talk can be  presented, \r\n\r\n1) Without Demos\r\n\r\n Time Duration: 20 mins\r\n\r\nTalk Structure:\r\n\r\n    General Discussion on What Is IoT and its future\r\n\r\n    The pros and cons of connecting things to the internet\r\n\r\n    How exploiters can breach the security and know our lifestyles\r\n\r\n     With a smart home rigged with cameras, can provide an intruder with victims' various details including lifestyles and visible passwords.That might result in identity theft with all the access codes including the biotech passwords.\r\n\r\n    Would suggest the methods for handling the security threats with channeled password inputs and multi-level user verification implementation.\r\n\r\n \r\n\r\n2) With Demos\r\n\r\nTime Duration: 30 mins\r\n\r\n \r\n\r\nTalk Structure:\r\n\r\n \r\n\r\n    Points discussed above (the ones without demo)\r\n\r\n    Implementing basic IoT attacks: During the session, we would implement some basic IOT attacks (eg. a quadcopter with development board mounted to demonstrate sniffing attacks, Hacking the FM frequency of participants).\r\n\r\n    Live demo & session on increasing security: Participants will learn how to increase the security and bypass few of these attacks.\r\n\r\n    along With this, we would also demonstrate to how to implement a multilevel security with a combination of UHF-RF ID, Biometrics and Voice recognition.\r\n\r\n    Taking steps beyond: We would also discuss the mechanism that can be adopted to ensure internet privacy. We would teach algorithms to generate real-time authentication keys using NFC and UHF-RF ID tags. We would also demonstrate the live development of scripts that can be used to implement dynamic key updates to ensure authorized access",
    "audience_level": "All",
    "author_id": "a277aaa4bd37fccf3aa03d1bb4634263",
    "tags": [
      ""
    ],
    "id": "c49a93d8f8dd2bb9a2b77613d29db3b1"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "New connectivity feature for IoT: API with multi-network SIM cards.",
    "abstract": "What would you think if you have the network coverage wherever your sensor are, your own independent cloud based network, extremely scalable and global. Nowadays SIM cards and endpoints can be easily managed in real-time via the intuitive user-interface or an easy-to-integrate API. \n",
    "description": "An implicit goal of developing applications is to increase the quality of life, or the general well-being of individuals and society as a whole.  In light of this a, new paradigm of the real-time communication between things has emerged, in which the quality of life of citizens in dense urban environments is increased through the use big data and cloud technology. The rapidly changing social and environmental order is becoming more complex as resources grow scarcer and populations increase, it requires just one technical integration point in IoT, which will provide technological fluency in the use big data for public benefit.  The proposal idea is the “wherever SIM” that provides the network coverage wherever devices may roam, has its own independent cloud based network, extremely scalable and global. SIM cards and endpoints can be easily managed in real-time via the intuitive user-interface or directly from the customer’s software application via an easy-to-integrate API for SIM cards. Key features, development and implementation stages, as well as use cases and code demonstration will be discussed.\r\n",
    "audience_level": "All",
    "author_id": "ead7ce3a4721450ad732c6831ab1a181",
    "tags": [
      "iot",
      "devops",
      "mobile",
      "messaging",
      "infrastructure",
      "connectivity",
      "implementation",
      "m2m",
      "api",
      "trending",
      "ioe",
      "iiot",
      ""
    ],
    "id": "71d943b773d2bff3095ca209e669b251"
  },
  {
    "talk_format": "Workshop (> 60 minutes)",
    "title": "scikit-learn: Machine Learning in Python",
    "abstract": "In this workshop we will discover discover scikit-learn a simple and efficient tool for data mining and data analysis. Scikit-learn provides a toolbox with solid implementations of a bunch of state-of-the-art models and makes it easy to plug them into our applications.",
    "description": "",
    "audience_level": "Intermediate",
    "author_id": "f28107b79ac542bc23cab0d2fd56b0ce",
    "tags": [
      "artificial intelligence",
      "data science",
      "data mining",
      "machine learning",
      ""
    ],
    "id": "d4806c8543c9c5ebe33941eba8e4c758"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "A Jupyter Enhancement Proposal Story",
    "abstract": "If you use Jupyter\nand don't like something on it,\nyou should know that you can contribute your idea to enhance the project.\nAt this talk you will learn how to submit a Jupyter Enhancement Proposals\nand share your idea.",
    "description": "Python users should be familiar with the concept of\r\n[Python Enhancement Proposals (PEPs)](https://www.python.org/dev/peps/),\r\nthe way that the Python language evolves over time.\r\nIn a similar fashion,\r\nthe Jupyter project has [Jupyter Enhancement Proposals (JEPs)](https://github.com/jupyter/enhancement-proposals).\r\nThis talk with cover the proposer first hand experience\r\nwhen submiting [JEP 23 - Add Template as Metatada enhancement proposal](https://github.com/jupyter/enhancement-proposals/pull/23)\r\nfrom it's begin,\r\nduring [EuroPython 2017](https://ep2017.europython.eu/),\r\nuntil the current status of it.",
    "audience_level": "All",
    "author_id": "496183698246ccaaec22894d81319fd1",
    "tags": [
      "e-learning",
      "Jupyter",
      "Jupyter Notebook",
      "Jupyter Enhancement Proposals",
      "community",
      ""
    ],
    "id": "ee4eeca02b1c762191ab125a49dc45d4"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "When VR meets Internet of things: Life beyond second life",
    "abstract": "imagine the possibilities that can exist if we were to we combine the worlds of Virtual Reality and Internet of Things This session will enable people with minimal knowledge of VR and basic IoT boards(such as Arduino, Raspberry Pi) to experience the best of the IoT & VR worlds. \n\n\n",
    "description": "\"It gets even more interesting when virtual and augmented reality meets the Internet of Things.\"  — Phil Repp\r\n\r\n \r\n\r\nIoT is taking over the technology industry with a huge bang! Our focus is to make the IoT smarter and more suitable for human interaction. Virtual Reality is the next billion dollar industry and it is the future of the Entertainment, Gaming and Education Industry. Now, imagine the possibilities that can exist if we were to we combine the worlds of Virtual Reality and Internet of Things This session will enable people with minimal knowledge of VR and basic IoT boards(such as Arduino, Raspberry Pi) to experience the best of the IoT & VR worlds. \r\n\r\n\r\nFurthermore, attendees will experience a remote tele-robotic presence as they transport and assume the identity of a web-connected robot, tasked with monitoring and maintaining atmospheric conditions.\r\n\r\n\r\n Along with the view of the place, the robot will be monitoring the nearby surroundings such as temperature, humidity and light intensity which will be then displayed along with the scenario displayed by VR device. Thus by this audience will learn how to Combine IoT with VR and hence make their own smart telepresence system like Jarvis.\r\n\r\n\r\n \r\n\r\nBy the end of the session, the audience will gain an increased understanding of the VR and IoT landscape, as well as how these technologies can be combined to give them an experience in life that was previously never-before-possible. A short Q&A session will be held after the [talk/workshop].",
    "audience_level": "All",
    "author_id": "9ecf8d590a47f752e6dd8254f79acee7",
    "tags": [
      ""
    ],
    "id": "b84a5385b02645f464c50bc141490267"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Machine Learning (ML) to Predict Responses",
    "abstract": "Minority Report was a 2002 American science fiction film based in 2054 where police officers apprehended criminals based on foreknowledge.  What we know today as Machine Learning (ML) is foreknowledge. Learn if we will ever reach a point where we can truly predict personalized human behavior. ",
    "description": "Minority Report was a 2002 American science fiction film based in 2054 where police officers apprehended criminals based on predictions and foreknowledge.  We are not in 2054, but fast-forward to 2017, we are closer than ever before to the world imagined in Minority Report. We are closer because of Machine Learning (ML), which in all intents and purposes can be considered foreknowledge. ML is a type of Artificial Intelligence (AI) that provides computers with the ability to learn without being explicitly programmed.  This thought is often scary because computers may soon have the potential to outlearn us and become smarter than their human makers.  The more data computers have, the smarter they become, and there is A LOT of data available. During this session, we will discuss how to use ML to generate predications that can be used in your applications and the inherent implications. ",
    "audience_level": "All",
    "author_id": "6fb022847405be48a26aabb520090347",
    "tags": [
      "machine learning",
      "artificial intelligence",
      ""
    ],
    "id": "74057809bddc384521aeea70ef78a045"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Combining AI and IoT. New Industrial Revolution in our houses and in the Universe",
    "abstract": "During last year we realized that Artificial Intelligence is functionally necessary to bring the number of sensor devices online. It definitely will be more important in making sense of data streamed in from IoT devices. What will happen when we will learn how to combine AI, IoT and general tools?",
    "description": "AI will be more important in making sense of data streamed in from IoT devices. What will happen when we will learn how to combine AI & IoT?\r\n\r\nThe Internet of Things (IoT) is converting the objects that surround us every day into a community of information that will increase the quality of our lives. From small devices to houses, the IoT is leading more and more things into the digital fold every day. Sensors are necessary to turn billions of objects into data-generating “things” that can report on their status, and in some cases, interact with their environment. \r\nAdvances in Artificial intelligence (AI) and the widespread availability of sensors have provided us with powerful applications that allow us to perform daily tasks by analyzing the huge amount of data. The insights to be gained from data are endless. In the light of this, a new paradigm of combining AI and IoT has emerged, in which the quality of life could be increased through the use of big data and cloud technology. \r\nThe talk includes a lot of real working IoT use cases and their potential impact of a combination IoT with AI. Their focus direct towards a more practical improvement of the quality of our life.",
    "audience_level": "Beginner",
    "author_id": "ead7ce3a4721450ad732c6831ab1a181",
    "tags": [
      "future",
      "connectivity",
      "ai",
      "case study",
      "methodology & architecture",
      "iot",
      ""
    ],
    "id": "287a4b05e25925234b2f78e70747e7d9"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Facial Recognition is Creeping into Daily Life",
    "abstract": "You may not know it, but facial recognition is already a part of our everyday lives. Wherever we go, we are being watched.  Facial recognition is integrated with social media, security, gaming, and commerce. Facial recognition technology has the ability to revolutionize the world as we know it. ",
    "description": "Facial recognition is everywhere from Facebook to security, gaming, stores, airports, etc. and its use is only growing.  Facial recognition is popular because face images exist of almost everyone.  You've got driver's license photos, identity badges from wherever you work, library cards, warehouse club cards, social media, and the list goes on. The FBI has said that by 2016, its database will include at least 4.3 million \"civil images\" — those taken for non-criminal purposes.  With the advent of several facial recognition APIs and the innovation leader, Amazon, throwing its hat in the ring with Amazon Rekognize, the technology will become even more common place than it is today.  Attend this talk to learn about advances in facial recognition and what it means for your life 1 year, 5 year, and even 10 years from now. After the talk, take a peek behind the scenes at an application that uses facial recognition.",
    "audience_level": "All",
    "author_id": "6fb022847405be48a26aabb520090347",
    "tags": [
      "facial recognition",
      "innovation",
      ""
    ],
    "id": "5e05fef9499e23d00e4bf89377d61430"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Augmented Reality (AR), not just for Pokemon Go",
    "abstract": "Augmented Reality (AR) is the emerging technology behind the Pokemon Go game craze.  Did you know that AR is not just for gaming? AR has many applicable uses in the real-world in industries like healthcare, education, the arts, museums, travel, supermarkets, etc. The impact list is far and wide.",
    "description": "Imagine the world around you coming to life like never before.  Augmented Reality (AR) is the emerging technology behind the Pokemon Go game craze.  Did you know that AR is not just for gaming? AR has many applicable uses in the real-world, from training surgeons, to selling real estate, to finding your next vacation destination, to helping you plan your next meal, to time travel (yes I said time travel), to even helping you \"cheat\" at pool.  The possibilities of how this technology can shape our world are limitless and should be explored from every angle.  Attend this talk to learn about advances in AR and what it means for your life 1 year, 5 year, and even 10 years from now. After the talk, view and demo application prototypes that will change how you view the world. ",
    "audience_level": "All",
    "author_id": "6fb022847405be48a26aabb520090347",
    "tags": [
      "augmented reality",
      ""
    ],
    "id": "06e2f5217ef0c5aef71812c2e3825daf"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "A Guide to Exponentiation, and How It Effects Machine Learning",
    "abstract": "Exponentiation: acme of math ops and tool of Machine Learning. Be it square or square root, exp, log, tanh, or the complex roots of unity, ** has it's work cut out. Ints, floats, fractions, matrices, complex, and zero don't play nice. See precision, accuracy, and performance down to the bits.  ",
    "description": "Mathematics of exponentiation and why data science cares (nearest neighbors and neural network activation functions, e.g logit/logistic)\r\n\r\nCalculation, precision, storage, representation and graphing all need to be considered, especially at scale. ** is prone to underflow and overflow with possibly dire consequences. It can even take longer to display the result of an exponentiation than to calculate it! Speed does matter when billions of calculations are being done.\r\n\r\nA very brief recap language and version differences\r\n\r\nThe CPython implementation of exponentiation is fairly convoluted n informative. Ironically, it is sometimes possible to successfully perform exponentiation with integers when floats will fail. As an operator becomes the function pow or ipow. Numerically help is needed at edge cases and so: exp -> expm1, sqrt -> hypot, log -> log1p, factorial -> gamma and Stirling, and why recursion is evil (especially for Fibonacci where an exponential comes to the rescue), and how caching might be useful.\r\n\r\nIn addition, numpy provides exp and exp2, ldexp and frexp, log2, logaddexp and logaddexp2, square and power, and each with interesting use cases.\r\n\r\nDid someone say matrix exponentiation? numpy.linalg.matrix_power scipy.linalg has expm, expm2, expm3, exmp_cond, expm_frechet.\r\n\r\nCryptography uses lots of modular exponentiation and tricks apply here.\r\n\r\nSolving the simple equation: x** y == y**x is challenging for both rational and real solutions. Graphing can help, with it's challenges of logarithmic scaling. We'll be examining the decimal, fractions, mpmath, bignum, and sympy modules for insights, workarounds and new gotchas.",
    "audience_level": "Beginner",
    "author_id": "d1cb32dde33859206e1c8b51c4d91e59",
    "tags": [
      "data science",
      "cryptography",
      "machine learning",
      "pattern recognition",
      ""
    ],
    "id": "52e415b4b828301226fb89aec3e5e3d6"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "SkData - Reproducibilidad en Análisis de Datos",
    "abstract": "SkData es un proyecto joven, de 2017, con la finalidad de facilitar el análisis de datos, proveyendo funcionalidades como:\n- limpieza de datos;\n- manipulación/tratamiento de los datos reproducible;\n- visualización de datos;",
    "description": "# SkData\r\n\r\nSkData es un proyecto joven, de 2017, con la finalidad de facilitar el análisis de datos, proveyendo funcionalidades como:\r\n\r\n- limpieza de datos;\r\n- manipulación/tratamiento de los datos reproducible;\r\n- visualización de datos;\r\n\r\n## Motivaciones\r\n\r\nLa construcción de la librería fue motivada por:\r\n\r\n- exceso de boilerplate en el análisis de datos;\r\n- el uso de librerías como pandas, matplotlib, scipy, etc puede ser difícil en un principio para no programadores;\r\n- en un escenario dónde la demanda es mayor que los recursos (personas, tiempo, etc) tener mecanismos que pueden agilizar el proceso de análisis de datos es fundamental.\r\n\r\n## Inspiraciones\r\n\r\nSkData se ha inspirado en funcionalidades de otros softwares como:\r\n\r\n- weka (http://www.cs.waikato.ac.nz/ml/weka/)\r\n- openrefine (http://openrefine.org/)\r\n\r\nLas visualizaciones gráficas en weka permiten de manera fácil entender las relaciones entre los atributos del conjunto de datos. El entendimiento previo de estas relaciones ayuda a determinar los pasos siguientes en el análisis de datos. Mientras que, generalmente, la programación de visualización de datos consume un poco de tiempo, tener un medio de hacerlo de manera automática, sin o con muy poco código, facilitaría mucho en el análisis de datos.\r\n\r\nLa limpieza/tratamiento de los datos pueden ser una tarea que consume mucho tiempo y, muchas veces, el proceso se repite en el análisis de distintos conjunto de datos. A parte de eso, tener el control de los pasos/manipulaciones de los datos, puede facilitar el proceso de análisis sin modificar los datos originales. OpenRefine provee estos recursos y muchas otras funcionalidades para limpieza de datos, así como funcionalidades como reconciliación de datos.",
    "audience_level": "All",
    "author_id": "7f0beb1fce4f057d5c482b1bc2665831",
    "tags": [
      "Data Science",
      "Data Analysis",
      "Python",
      "Data Cleaning",
      "Jupyter Widget",
      "Data Visualization",
      ""
    ],
    "id": "49f51cc85392ecd4a726750e83ff1a54"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Securing Smart Homes with Tor",
    "abstract": "The IoT is emerging as the third wave in the development of the Internet. We have a great danger with IoT because of the surveillance by an individual hacker or a state actor to exploit the very private information of individuals or companies. We can secure our “Smart Homes” by using Tor.",
    "description": "Recent advances in information and communication technologies and embedded systems have given rise to a new disruptive technology: the Internet of Things (IoT). Internet of things (IoT) is expected to have a massive impact on consumer products, business and wider culture, but these are still early days.\r\n\r\nThe Internet of Things is a phenomenon where tiny machines have the ability to sense, respond, compute, and connect to the Internet, providing unprecedented access to control things and the environment around us. Along with advancement lies the problem going hand-to-hand.There have been many reports on how this things can be exploited to do various things in the Digital World.We need security because we don’t want others to control our home or disturb our privacy in our homes. Tor having been helping many people towards “Safe and Secure Browsing”. We can use “Tor” for securing our “Smart Home” so that we may not face the situations where we locked out by our home.\r\n\r\nSecurity is extremely important for achieving this goal. As this worldwide network of interconnected objects can be exploited anywhere by anyone and anytime, it is necessary to enhance it with strong security foundations able to give birth to a world-changing paradigm.\r\n\r\nThe sense of fear that arises when using “Smart Homes” is addressed since, recently we have seen the “Dark Side” of Smart Homes and Internet of Things where people became aware of the risks of using more “IoT” which makes them more vulnerable and also effects their privacy.",
    "audience_level": "All",
    "author_id": "fafb2a5b8bbf6ee183f150606e5f0277",
    "tags": [
      "smart homes",
      "internet of things",
      "raspberrypi",
      "privacy",
      "tor",
      "cryptography",
      "security",
      "iot",
      "python",
      ""
    ],
    "id": "1d4e2c01065efd6592537504a50513e3"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "The Future of Internet Services",
    "abstract": "Hands-free and screen-free is the future of Internet services due to the Artificial Intelligence (AI) discipline of natural language processing, which parses grammar and syntax. Amazon Alexa is leading the charge to a hands-free and screen future and will soon be able to recognize your emotions.",
    "description": "Hands-free and screen-free is the future of Internet services due to the Artificial Intelligence (AI) discipline of natural language processing, which parses grammar and syntax. Amazon Alexa is leading the charge to a hands-free and screen future and will soon be able to recognize your emotions.  Amazon initially launched the Echo, with relatively low fanfare in 2014;  however, fast forward to 2017, the device is a sure fire hit and has caused competitors to take notice.  The device seems to realize the promise of voice as a more natural and frictionless way to interact with technology bringing the hands-free and screen-free future to present day.  During this talk, learn how to interact with Amazon Alexa through the Echo device and how to teach this technology to become smarter and to naturally learn and grow. \r\n\r\n",
    "audience_level": "All",
    "author_id": "6fb022847405be48a26aabb520090347",
    "tags": [
      "amazon",
      "aws",
      "alexa",
      "echo",
      "ai",
      "artificial intelligence",
      ""
    ],
    "id": "35a31a3d8962fd5618454bae028ccec6"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Smart Anomaly Detection for your Python Django App with Azure Application Insights",
    "abstract": "Azure Application Insights recently enabled support for Django web apps to Python SDK. With simple onboarding steps you can now utilize the full power of Application Insights platform to auto-detect performance and failure anomalies and configure monitoring and diagnostics for your Django app.",
    "description": "Azure Application Insights offers rich and rapidly growing anomaly detection capabilities, based on machine learning and statistical analysis. During the talk I will give an overview of what kind of problems are detected and then go through the steps of onboarding Django app to Application Insights, using our Python SDK to add custom telemetry, generating fake load with anomalous patterns and exploring smart detection results in Azure portal. \r\nThe talk assumes knowledge of Python, Django and basic familiarity with cluster analysis.",
    "audience_level": "All",
    "author_id": "f159dd33faed66eb7324f6ba53f41f58",
    "tags": [
      "big data",
      "cloud computing",
      "python",
      "django",
      "clustering",
      "statistics",
      ""
    ],
    "id": "bf65f6d54c6d01ce8091b6cd0147feca"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "The Python Interactive Dashboards Landscape",
    "abstract": "Several Python-based tools are beginning to emerge as significant contenders for the generation of customized interactive dashboards. This talk consists of comparing the main alternatives using an example of public interest data visualization showing advantages and disadvantages in each case",
    "description": "# The Python Interactive Dashboards Landscape\r\n\r\nSimilar to Jake Vanderplas's recent talk on \"The Python visualization landscape\", this proposal aims to organize the information around the different alternatives available in Python for the generation of interactive dashboards. There is a long experience in Management Science in the use of dashboards to facilitate the visualization of performance indicators of specific processes of an organization or the organization as a whole. In this context, there are several Python-based tools that are beginning to emerge as important contenders in the domain of customized dashboards, long monopolized by proprietary applications such as Tableau. This talk consists of reviewing some of the main alternatives using as reference an example of public interest data visualization and establishing a comparative and reviewing the advantages and disadvantages in each case.\r\n\r\nIt is important to set the context of desirable features for interactive dashboard construction, the relationship with Python's analytical tools, and the ease of customizing and deploying developed applications. Among the tools to consider are the Jupyter dashboard extension, the Dash tool developed under the Plot.ly project, the Superset application developed by Airbnb and currently incubated by the Apache Foundation, and the Bokeh visualization tool. It also mentions some tools that can be found in github and similar repositories that are proposed as particular or incipient solutions to address this same need, where one of the most relevant examples is Dataviva, a portal with open data on the Brazilian economy.\r\n\r\nThis talk discusses the relationship of these tools to the development of decision support systems and the evidence- and performance-led management decision-making process. In particular, it is argued that the flexibility offered by Python-based tools is best suited to user stories associated with the use of dashboards in organizations.\r\n",
    "audience_level": "All",
    "author_id": "7bbdf7e75f91b6b1c36f89c106baf71f",
    "tags": [
      "business intelligence",
      "strategic information systems",
      "tool integration",
      "decision support sytems",
      ""
    ],
    "id": "16fa305e4a0a370b6cb1367ddc933a1f"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Find the Farm (Data Science Insights into Real Estate Pricing)",
    "abstract": "Real estate transactions are geographically and temporally sparse. Pricing models traditionally rely on only physical parameters; omitting realtor effects, listing or selling. Realtor farms found by cluster identification, are analyzed for negotiation strength in listing vs sales prices",
    "description": "Using gmplot, geopy, and Python data science tools we'll discover realtor farms, and assess the characteristics of sales vs listing price. Real estate transactions tend to be geographically sparse and temporally rare. There is often both a listing and a selling agent in the representing a given property. The sales price is determined by a number of factor. While there has been considerable interest in building pricing models relying on physical parameters, there has been little work done in assessing the contribution of the realtor. The discovery of a 'farm' uses cluster identification methods. These farms can then be analyzed for imputed listing prices and the sales price, both of which are negotiated.\r\n\r\nThe problem: Most real estate analytics deal only with property description and location. Markets can swing quickly from buyer's to seller's advantage, so timing and days on market is important. Agent effects are not well understood and can be a significant factor in determining the actual price. Data source are examined . Python Modules utilized. Application of data science, e.g. modules pycluster, pyclustering, scikit-learn. (the talk is primarily application, not theory)\r\n\r\nExamples of geographic and hidden affinity Analysis of listing price to appraisal and listing agent effect Analysis of over/under-performance of sales price to listing price Determination of listing agent vs selling agent negotiation skills. Effect of dual agency on pricing. Effect of listing agent Farms on neighborhood pricing.\r\n\r\nConsideration as a Machine Learning project using Theano or TensorFlow , Keras, Sonnet tflearn\r\n\r\nConclusions and future directions Questions\r\n\r\ndata, code, notebooks, and graphics will be included\r\n\r\nThe methodology presented is likely applicable to other low-volume high-value facilitated transactions.  ",
    "audience_level": "All",
    "author_id": "d1cb32dde33859206e1c8b51c4d91e59",
    "tags": [
      "predict market behavior",
      ""
    ],
    "id": "b2d1543e3a0bbad2fc5bd5156eba9023"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Artificial Intelligence – What could go wrong?",
    "abstract": "AI can spot you in a crowd (even when you’re wearing a mask) tell your sexual orientation from images and is trained from public data sets. What could go wrong?",
    "description": "Artificial Intelligence is an exciting and (over?) hyped field. We're beginning to see some really exciting capabilities, as well as some worrying ones.\r\n\r\nSome of these we face in the short term are biased algorithms, powerful surveillance, autonomous weapons and vulnerable AI systems. \r\n\r\nThere are many unknowns; if you create an intelligent system, how do you align it's values to your own? And if you are Iran...",
    "audience_level": "All",
    "author_id": "c858bcab81880f494eef6bbfd8ac904e",
    "tags": [
      "ai and machine learning",
      "privacy",
      "security",
      "open data: issues",
      ""
    ],
    "id": "536c35826d0c12b68e549241e70ca965"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "Web Based Virtual Reality using A-Frame",
    "abstract": "Virtual Reality is undoubtedly one of the most sought after technology of the present times. It is more interesting when people get to know the ease of making Web based VR. My talk will introduce Web Based Virtual Reality which makes developing VR websites, a cakewalk for Web developers.",
    "description": "\r\n\r\nUnderstanding Virtual Reality is important because it is the next big thing and the huge number of web developers need to be aware of the ease with which they can build VR websites. With technology getting closer to the human imagination, it’s hard to give up even on the slightest chance of getting involved in the making of it.\r\n\r\nThe talk shall unfold as following:\r\n\r\n  *  What is VR/ web based VR ?\r\n  *  What is A-Frame?\r\n  *  The WebVR API and A-Frame library\r\n\r\nA-Frame is a web framework for building virtual reality experiences with with HTML and Entity-Component. Amidst the big debate on web vs app, it’s hard to give up on the luring features of either of those. Both have their own pros and cons. What if there was a way to combine their pros and almost eliminate the cons. Progressive Web Apps (PWAs) show the way forward.\r\n\r\nUnderstanding and building PWAs is important because the next wave of top developers is creating web applications that can reach heights, native apps cannot. With technology getting closer to the human imagination, it’s hard to give up even on the slightest chance of advancement in saving our time and resources while getting our job done.\r\n\r\n  *  Live demo\r\n  *  Start building VR websites\r\n\r\n",
    "audience_level": "Beginner",
    "author_id": "42ccd932dfa6e3ca0d5f911f7a238456",
    "tags": [
      "WebVR Virtual Reality",
      "MobileVR",
      "AFrame",
      "WebGL",
      "Mobile",
      ""
    ],
    "id": "620715751c819f889439d0bc9f3fd0e2"
  },
  {
    "talk_format": "Lightning Talk (~5-10 minutes)",
    "title": "How the real-time communication between things can simplify our everyday life: make it more secure and economic",
    "abstract": "An implicit goal of developing applications in IoT is to increase the quality of life. The rapidly changing social and environmental order is becoming more complex, it requires one technical integration point in IoT, which will provide technological fluency in the use big data for public benefit.  ",
    "description": "An implicit goal of developing applications in IoT is to increase the quality of life, or the general well-being of individuals and society as a whole. The insights to be gained from data are endless. In light of this a, new paradigm of the real-time communication between things has emerged, in which the quality of life of citizens in dense urban environments is increased through the security of use big data and cloud technology. Future cities are likely to feature thousands of strategically placed sensors that would record everything from air pressure and temperature to microbial content, and the data would be relayed instantly to the laptops of actively participating smart citizens, who will make critical contributions to urban planning, reducing pollution, and making the best use of finite resources.\r\nThe rapidly changing social and environmental order is becoming more complex as resources grow scarcer and populations increase, it requires just one secure technical integration point in IoT, which will provide technological fluency in the use big data for public benefit.  The proposal solution is the mobile connectivity that provides the network coverage wherever devices may roam. Secure cellular connection together with SIM cards and endpoints can be easily managed in real-time via the intuitive user-interface or directly from the customer’s software application via an easy-to-integrate API. Key features, development and implementation stages, as well as use cases will be discussed.",
    "audience_level": "All",
    "author_id": "ead7ce3a4721450ad732c6831ab1a181",
    "tags": [
      "devops",
      "frontend",
      "iot",
      "wearable",
      "mobile",
      ""
    ],
    "id": "c8e726b0a5b6cd07289d169c7b1e8143"
  },
  {
    "talk_format": "Talk (~30-45 minutes)",
    "title": "José Martí en la era digital",
    "abstract": "La presentación aborda el contexto científico y tecnológico en que el Apóstol cubano desarrolló su vida patriótica en pos de una nación independiente y próspera, así como los descubrimientos relacionados con la comunicación de su época y la actitud que asumiría si viviera la era digital.",
    "description": "La presentación contiene un grupo de imágenes y audiovisuales relacionados con la era de Guttemberg y la era digital, que representan las circunstancias históricas, estéticas y tecnológicas del contexto cultural en que se desarrolló José Martí, así como las evidencias de que si nos acompañara desempeñaría una función divulgadora y educativa a partir de los recursos informáticos.",
    "audience_level": "Beginner",
    "author_id": "85ae73e1a8d68f5504dd2166c6960453",
    "tags": [
      "estética",
      "comunicación",
      "era digital",
      "educación",
      "ética",
      ""
    ],
    "id": "4dce29a58e55d2bf5751f26048a57084"
  },
  {}
]
